"""
Fixer Agent - Automated Security Fix Generator
=================================================
Takes confirmed findings from the Analyzer Agent and generates
security fixes as draft Pull Requests on GitHub.

Pipeline: For each confirmed finding:
  1. Read the vulnerable source file (to get content + SHA)
  2. Generate fix via LLM
  3. Create security/ branch
  4. Commit the fixed file
  5. Create draft PR with vulnerability details

Usage:
    python fixer.py
    python fixer.py --input ../analyzer/reports/analyzer-output.json
    python fixer.py --input analysis.json --output reports/fixer-output.json
    python fixer.py --dry-run  (generate fixes but don't push to GitHub)
"""

import argparse
import asyncio
import json
import os
import re
import sys
from datetime import datetime, timezone

from config import (
    FIXER_VERSION,
    GITHUB_OWNER,
    GITHUB_REPO,
    BRANCH_PREFIX,
    DEFAULT_ANALYZER_INPUT,
    DEFAULT_FIXER_OUTPUT,
)
from github_client import (
    read_file_content,
    create_branch,
    update_file,
    create_pull_request,
)
from llm_engine import generate_fix


def load_analyzer_findings(input_path: str) -> tuple[list[dict], dict]:
    """Load confirmed findings from analyzer output JSON.

    Returns:
        Tuple of (confirmed findings list, full report dict)
    """
    if not os.path.exists(input_path):
        print(f"  [!] Analyzer output not found: {input_path}")
        print(f"  [!] Run the analyzer first: cd ../analyzer && python analyzer.py")
        sys.exit(1)

    with open(input_path, "r") as f:
        report = json.load(f)

    all_findings = report.get("findings", [])
    if not all_findings:
        print("  [!] No findings in analyzer output - nothing to fix")
        sys.exit(0)

    # Only fix CONFIRMED findings
    confirmed = [f for f in all_findings if f.get("verdict") == "CONFIRMED"]
    if not confirmed:
        print("  [OK] No CONFIRMED findings - all false positives. Nothing to fix!")
        sys.exit(0)

    return confirmed, report


def _slugify(text: str) -> str:
    """Convert text to a branch-safe slug."""
    slug = text.lower().strip()
    slug = re.sub(r'[^a-z0-9]+', '-', slug)
    slug = slug.strip('-')
    return slug[:50]  # Max 50 chars


def make_branch_name(finding: dict) -> str:
    """Generate branch name from finding: security/fix-{vuln-slug}."""
    vuln = finding.get("vulnerability", "unknown")
    file_name = os.path.basename(finding.get("file", "unknown"))
    name_part = os.path.splitext(file_name)[0]
    slug = _slugify(f"fix-{vuln}-{name_part}")
    return f"{BRANCH_PREFIX}/{slug}"


def make_commit_message(finding: dict) -> str:
    """Generate commit message for the fix."""
    vuln = finding.get("vulnerability", "Security Fix")
    file_path = finding.get("file", "")
    cwe = finding.get("cwe", "")
    return f"fix: remediate {vuln} in {os.path.basename(file_path)} ({cwe})"


def make_pr_body(finding: dict, fix_details: str) -> str:
    """Generate PR description with vulnerability details."""
    return (
        f"## Security Fix: {finding.get('vulnerability', 'Unknown')}\n\n"
        f"**Generated by**: DevSecOps Guardian - Fixer Agent v{FIXER_VERSION}\n\n"
        f"### Vulnerability Details\n"
        f"| Field | Value |\n"
        f"|-------|-------|\n"
        f"| **Scan ID** | {finding.get('scan_id', 'N/A')} |\n"
        f"| **Analysis ID** | {finding.get('anlz_id', 'N/A')} |\n"
        f"| **CWE** | {finding.get('cwe', 'N/A')} |\n"
        f"| **Severity** | {finding.get('severity', 'N/A')} |\n"
        f"| **Exploitability** | {finding.get('exploitability_score', 'N/A')}/100 |\n"
        f"| **File** | `{finding.get('file', 'N/A')}` |\n"
        f"| **Line** | {finding.get('line', 'N/A')} |\n\n"
        f"### Description\n"
        f"{finding.get('description', 'N/A')}\n\n"
        f"### Attack Scenario\n"
        f"{finding.get('attack_scenario', 'N/A')}\n\n"
        f"### Fix Applied\n"
        f"{fix_details}\n\n"
        f"### Auth Context\n"
        f"{finding.get('auth_context', 'N/A')}\n\n"
        f"---\n"
        f"**IMPORTANT**: This is a DRAFT PR generated by AI. "
        f"A human developer must review and approve before merging.\n\n"
        f"*DevSecOps Guardian - Automated Security Pipeline*"
    )


def make_pr_title(finding: dict) -> str:
    """Generate PR title."""
    vuln = finding.get("vulnerability", "Security Fix")
    file_name = os.path.basename(finding.get("file", ""))
    cwe = finding.get("cwe", "")
    return f"fix: {vuln} in {file_name} ({cwe})"


async def process_finding(finding: dict, ref: str = None, dry_run: bool = False) -> dict:
    """Process a single confirmed finding: generate fix, create branch + PR.

    Returns a result dict with fix status and PR info.
    """
    scan_id = finding.get("scan_id", "???")
    file_path = finding.get("file", "")
    vuln = finding.get("vulnerability", "???")

    result = {
        "scan_id": scan_id,
        "anlz_id": finding.get("anlz_id", ""),
        "file": file_path,
        "vulnerability": vuln,
        "status": "FAILED",
        "fix_summary": "",
        "fixed_code": "",
        "fix_explanation": "",
        "fix_error": "",
        "branch": "",
        "pr_number": None,
        "pr_url": "",
        "error": "",
    }

    try:
        # Step 1: Read the vulnerable source file
        print(f"\n  --- {scan_id}: {vuln} ({file_path}) ---")
        print(f"  [1/5] Reading source file from GitHub...")
        file_data = await read_file_content(file_path, ref)
        if not file_data or not file_data.get("content"):
            result["error"] = f"Could not read {file_path}"
            return result

        source_code = file_data["content"]
        file_sha = file_data["sha"]
        print(f"  [1/5] Read {len(source_code)} chars, SHA: {file_sha[:8]}...")

        # Step 2: Generate fix via LLM
        print(f"  [2/5] Generating fix with LLM...")
        fix = await generate_fix(finding, source_code)
        if not fix or not fix.get("fixed_code"):
            result["fix_error"] = "LLM failed to generate fix code"
            result["error"] = "LLM failed to generate fix"
            return result

        result["fix_summary"] = fix.get("fix_summary", "")
        result["fixed_code"] = fix.get("fixed_code", "")
        result["fix_explanation"] = fix.get("fix_details", "")

        if dry_run:
            result["status"] = "DRY_RUN"
            print(f"  [DRY RUN] Fix generated but not pushed to GitHub")
            return result

        # Step 3: Create security branch
        branch_name = make_branch_name(finding)
        print(f"  [3/5] Creating branch: {branch_name}")
        branch_result = await create_branch(branch_name)
        if not branch_result:
            # Branch may already exist from a previous run - try to proceed
            print(f"  [~] Branch may already exist, attempting to commit anyway...")

        result["branch"] = branch_name

        # Step 4: Commit the fixed file
        commit_msg = make_commit_message(finding)
        print(f"  [4/5] Committing fix: {commit_msg}")
        commit_result = await update_file(
            file_path=file_path,
            content=fix["fixed_code"],
            message=commit_msg,
            branch=branch_name,
            sha=file_sha,
        )
        if not commit_result:
            result["error"] = "Failed to commit fix to GitHub"
            return result

        print(f"  [4/5] Committed: {commit_result.get('commit_sha', '???')[:8]}...")

        # Step 5: Create draft PR
        pr_title = make_pr_title(finding)
        pr_body = make_pr_body(finding, fix.get("fix_details", ""))
        print(f"  [5/5] Creating draft PR: {pr_title}")
        pr_result = await create_pull_request(
            title=pr_title,
            body=pr_body,
            head_branch=branch_name,
            draft=True,
        )

        if pr_result:
            result["pr_number"] = pr_result.get("pr_number")
            result["pr_url"] = pr_result.get("html_url", "")
            result["status"] = "SUCCESS"
            print(f"  [5/5] PR #{result['pr_number']}: {result['pr_url']}")
        else:
            # Fix was committed but PR creation failed
            result["status"] = "FIX_GENERATED"
            result["fix_error"] = "Fix code generated and committed but PR creation failed"

        return result

    except Exception as e:
        result["error"] = str(e)
        print(f"  [!] Error processing {scan_id}: {e}")
        return result


def print_results(results: list[dict]):
    """Pretty-print fix results to console."""
    if not results:
        print("\n  [OK] No findings to fix!")
        return

    print(f"\n{'='*60}")
    print(f"  FIXER RESULTS: {len(results)} findings processed")
    print(f"{'='*60}")

    for r in results:
        status = r["status"]
        if status == "SUCCESS":
            icon = "[OK]"
        elif status == "DRY_RUN":
            icon = "[~]"
        elif status == "PARTIAL":
            icon = "[!]"
        elif status == "FIX_GENERATED":
            icon = "[~]"
        else:
            icon = "[!!]"

        print(f"\n  {icon} [{status}] {r['scan_id']}: {r['vulnerability']}")
        print(f"       File: {r['file']}")

        if r.get("fix_summary"):
            print(f"       Fix: {r['fix_summary']}")
        if r.get("branch"):
            print(f"       Branch: {r['branch']}")
        if r.get("pr_number"):
            print(f"       PR: #{r['pr_number']} - {r['pr_url']}")
        if r.get("error"):
            print(f"       Error: {r['error']}")

    # Summary
    success = sum(1 for r in results if r["status"] == "SUCCESS")
    dry_run = sum(1 for r in results if r["status"] == "DRY_RUN")
    partial = sum(1 for r in results if r["status"] == "PARTIAL")
    fix_generated = sum(1 for r in results if r["status"] == "FIX_GENERATED")
    failed = sum(1 for r in results if r["status"] == "FAILED")

    parts = []
    if success:
        parts.append(f"{success} SUCCESS")
    if dry_run:
        parts.append(f"{dry_run} DRY_RUN")
    if partial:
        parts.append(f"{partial} PARTIAL")
    if fix_generated:
        parts.append(f"{fix_generated} FIX_GENERATED")
    if failed:
        parts.append(f"{failed} FAILED")

    print(f"\n  Summary: {' | '.join(parts)}")


def save_report(results: list[dict], analyzer_input: str, output_path: str):
    """Save fixer results to JSON file."""
    success = sum(1 for r in results if r["status"] == "SUCCESS")
    failed = sum(1 for r in results if r["status"] in ("FAILED", "PARTIAL"))

    report = {
        "agent_name": "DevSecOps Guardian - Fixer Agent",
        "version": FIXER_VERSION,
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "repository": f"{GITHUB_OWNER}/{GITHUB_REPO}",
        "analyzer_report": analyzer_input,
        "total_processed": len(results),
        "success_count": success,
        "failed_count": failed,
        "fixes": results,
    }

    os.makedirs(os.path.dirname(output_path) or ".", exist_ok=True)
    with open(output_path, "w") as f:
        json.dump(report, f, indent=2)

    print(f"\n  [*] Results saved to: {output_path}")


async def main():
    parser = argparse.ArgumentParser(description="DevSecOps Guardian - Fixer Agent")
    parser.add_argument(
        "--input", type=str, default=DEFAULT_ANALYZER_INPUT,
        help="Path to analyzer JSON output file"
    )
    parser.add_argument(
        "--output", type=str, default=DEFAULT_FIXER_OUTPUT,
        help="Output JSON file path"
    )
    parser.add_argument("--ref", type=str, help="Branch or commit SHA for reading source files")
    parser.add_argument(
        "--dry-run", action="store_true",
        help="Generate fixes but do not push to GitHub (no branches, commits, or PRs)"
    )

    args = parser.parse_args()

    # Resolve input path
    input_path = os.path.abspath(args.input)

    # Header
    mode = "Dry Run (no GitHub writes)" if args.dry_run else "Full (branch + commit + PR)"
    print(f"\n{'='*60}")
    print(f"  DevSecOps Guardian - Fixer Agent")
    print(f"  Analyzer Input: {args.input}")
    print(f"  Mode: {mode}")
    print(f"  Time: {datetime.now(timezone.utc).isoformat()}")
    print(f"{'='*60}\n")

    # Phase 1: Load confirmed findings
    print("[1/2] Loading confirmed findings from analyzer...")
    confirmed_findings, analyzer_report = load_analyzer_findings(input_path)
    print(f"  Found {len(confirmed_findings)} CONFIRMED findings to fix")

    # Phase 2: Process each finding
    print(f"\n[2/2] Processing {len(confirmed_findings)} findings...")
    results = []
    for i, finding in enumerate(confirmed_findings, 1):
        print(f"\n{'- '*30}")
        print(f"  Finding {i}/{len(confirmed_findings)}")
        result = await process_finding(finding, args.ref, args.dry_run)
        results.append(result)

    # Output
    print_results(results)
    save_report(results, args.input, args.output)


if __name__ == "__main__":
    asyncio.run(main())
