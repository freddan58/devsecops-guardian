"""
Compliance Agent - PCI-DSS 4.0 Audit Report Generator
=======================================================
Takes the complete pipeline output (Scanner + Analyzer + Fixer)
and generates audit-ready compliance reports mapped to PCI-DSS 4.0.

Pipeline inputs:
  - Scanner output: raw findings
  - Analyzer output: confirmed findings with triage
  - Fixer output: fix status, branches, draft PRs

Outputs:
  - compliance-output.json: Structured assessment data
  - compliance-report.md: Audit-ready Markdown report

Usage:
    python compliance.py
    python compliance.py --scanner ../scanner/reports/scanner-output.json
    python compliance.py --analyzer ../analyzer/reports/analyzer-output.json
    python compliance.py --fixer ../fixer/reports/fixer-output.json
"""

import argparse
import asyncio
import json
import os
import sys
from datetime import datetime, timezone

from config import (
    COMPLIANCE_VERSION,
    GITHUB_OWNER,
    GITHUB_REPO,
    DEFAULT_SCANNER_INPUT,
    DEFAULT_ANALYZER_INPUT,
    DEFAULT_FIXER_INPUT,
    DEFAULT_COMPLIANCE_OUTPUT_JSON,
    DEFAULT_COMPLIANCE_OUTPUT_MD,
)
from llm_engine import generate_compliance_assessment


def load_json_report(path: str, agent_name: str) -> dict:
    """Load a JSON report file, with helpful error messages."""
    abs_path = os.path.abspath(path)
    if not os.path.exists(abs_path):
        print(f"  [!] {agent_name} output not found: {abs_path}")
        print(f"  [!] Run the {agent_name.lower()} first")
        return {}

    with open(abs_path, "r") as f:
        return json.load(f)


def load_pipeline_data(scanner_path: str, analyzer_path: str, fixer_path: str) -> tuple:
    """Load all upstream agent outputs.

    Returns:
        (analyzer_findings, fixer_results, pipeline_metadata)
    """
    # Scanner report (optional - mainly for metadata)
    scanner_report = load_json_report(scanner_path, "Scanner")

    # Analyzer report (required - has confirmed findings)
    analyzer_report = load_json_report(analyzer_path, "Analyzer")
    if not analyzer_report:
        print("  [!] Analyzer output is required for compliance assessment")
        sys.exit(1)

    # Fixer report (optional - enriches with fix status)
    fixer_report = load_json_report(fixer_path, "Fixer")

    # Extract confirmed findings from analyzer
    all_findings = analyzer_report.get("findings", [])
    confirmed_findings = [f for f in all_findings if f.get("verdict") == "CONFIRMED"]

    if not confirmed_findings:
        print("  [OK] No confirmed findings - compliance report will reflect clean state")

    # Extract fixer results
    fixer_results = fixer_report.get("fixes", [])

    # Build metadata from all sources
    pipeline_metadata = {
        "repository": f"{GITHUB_OWNER}/{GITHUB_REPO}",
        "scan_timestamp": scanner_report.get("timestamp", analyzer_report.get("timestamp", "")),
        "scanner_total": scanner_report.get("total_findings", len(all_findings)),
        "false_positive_count": analyzer_report.get("false_positive_count", 0),
    }

    return confirmed_findings, fixer_results, pipeline_metadata


def generate_markdown_report(assessment: dict, pipeline_metadata: dict) -> str:
    """Generate an audit-ready Markdown compliance report."""
    now = datetime.now(timezone.utc).isoformat()
    repo = pipeline_metadata.get("repository", "N/A")

    lines = []
    lines.append("# PCI-DSS 4.0 Compliance Assessment Report")
    lines.append("")
    lines.append("---")
    lines.append("")
    lines.append("## Report Metadata")
    lines.append("")
    lines.append(f"| Field | Value |")
    lines.append(f"|-------|-------|")
    lines.append(f"| **Generated By** | DevSecOps Guardian - Compliance Agent v{COMPLIANCE_VERSION} |")
    lines.append(f"| **Report Date** | {now} |")
    lines.append(f"| **Repository** | {repo} |")
    lines.append(f"| **Framework** | PCI-DSS 4.0 |")
    lines.append(f"| **Overall Risk Rating** | **{assessment.get('overall_risk_rating', 'N/A')}** |")
    lines.append(f"| **Findings Assessed** | {len(assessment.get('findings', []))} |")
    lines.append(f"| **Non-Compliant Controls** | {assessment.get('non_compliant_count', 'N/A')} |")
    lines.append(f"| **Compliant Controls** | {assessment.get('compliant_count', 'N/A')} |")
    lines.append("")

    # Executive Summary
    lines.append("## Executive Summary")
    lines.append("")
    lines.append(assessment.get("executive_summary", "No executive summary available."))
    lines.append("")

    # Pipeline Summary
    scanner_total = pipeline_metadata.get("scanner_total", 0)
    false_pos = pipeline_metadata.get("false_positive_count", 0)
    lines.append("## Security Pipeline Summary")
    lines.append("")
    lines.append(f"| Pipeline Stage | Result |")
    lines.append(f"|---------------|--------|")
    lines.append(f"| Scanner Agent | {scanner_total} potential findings detected |")
    lines.append(f"| Analyzer Agent | {len(assessment.get('findings', []))} confirmed, {false_pos} false positives eliminated |")
    lines.append(f"| Fixer Agent | Draft PRs created for confirmed findings |")
    lines.append(f"| Compliance Agent | PCI-DSS 4.0 mapping and assessment (this report) |")
    lines.append("")

    # Detailed Findings
    lines.append("## Detailed Findings and PCI-DSS Mapping")
    lines.append("")

    for finding in assessment.get("findings", []):
        scan_id = finding.get("scan_id", "N/A")
        vuln = finding.get("vulnerability", "Unknown")
        cwe = finding.get("cwe", "N/A")
        severity = finding.get("severity", "N/A")
        risk = finding.get("risk_rating", "N/A")

        lines.append(f"### {scan_id}: {vuln}")
        lines.append("")
        lines.append(f"| Field | Value |")
        lines.append(f"|-------|-------|")
        lines.append(f"| **CWE** | {cwe} |")
        lines.append(f"| **Severity** | {severity} |")
        lines.append(f"| **Risk Rating** | {risk} |")
        lines.append("")

        if finding.get("risk_justification"):
            lines.append(f"**Risk Justification**: {finding['risk_justification']}")
            lines.append("")

        if finding.get("regulatory_impact"):
            lines.append(f"**Regulatory Impact**: {finding['regulatory_impact']}")
            lines.append("")

        # PCI-DSS Requirements Table
        reqs = finding.get("pci_dss_requirements", [])
        if reqs:
            lines.append("**PCI-DSS 4.0 Requirements:**")
            lines.append("")
            lines.append("| Requirement | Title | Status | Remediation |")
            lines.append("|------------|-------|--------|-------------|")
            for req in reqs:
                req_id = req.get("requirement_id", "N/A")
                title = req.get("requirement_title", "N/A")
                status = req.get("compliance_status", "N/A")
                remed = req.get("remediation_status", "N/A")
                lines.append(f"| {req_id} | {title} | **{status}** | {remed} |")
            lines.append("")

            # Evidence details
            for req in reqs:
                req_id = req.get("requirement_id", "")
                evidence = req.get("evidence", "")
                relevance = req.get("relevance", "")
                remed_ev = req.get("remediation_evidence", "")

                if evidence or relevance:
                    lines.append(f"**Req {req_id}**:")
                    if relevance:
                        lines.append(f"- Relevance: {relevance}")
                    if evidence:
                        lines.append(f"- Evidence: {evidence}")
                    if remed_ev:
                        lines.append(f"- Remediation: {remed_ev}")
                    lines.append("")

        lines.append("---")
        lines.append("")

    # Recommendations
    recommendations = assessment.get("recommendations", [])
    if recommendations:
        lines.append("## Recommendations")
        lines.append("")
        for i, rec in enumerate(recommendations, 1):
            lines.append(f"{i}. {rec}")
        lines.append("")

    # Footer
    lines.append("---")
    lines.append("")
    lines.append("*This report was generated by DevSecOps Guardian - an AI-powered multi-agent security pipeline.*")
    lines.append(f"*Report generated: {now}*")
    lines.append("")
    lines.append("**IMPORTANT**: This automated assessment should be reviewed by a qualified PCI-DSS QSA (Qualified Security Assessor) before being used for formal compliance certification.")

    return "\n".join(lines)


def print_assessment(assessment: dict):
    """Pretty-print compliance assessment to console."""
    findings = assessment.get("findings", [])

    print(f"\n{'='*60}")
    print(f"  PCI-DSS 4.0 COMPLIANCE ASSESSMENT")
    print(f"  Overall Risk: {assessment.get('overall_risk_rating', 'N/A')}")
    print(f"  Findings: {len(findings)} | Non-Compliant: {assessment.get('non_compliant_count', 0)}")
    print(f"{'='*60}")

    for finding in findings:
        scan_id = finding.get("scan_id", "N/A")
        vuln = finding.get("vulnerability", "Unknown")
        risk = finding.get("risk_rating", "N/A")

        if risk == "CRITICAL":
            icon = "[!!]"
        elif risk == "HIGH":
            icon = "[!]"
        elif risk == "MEDIUM":
            icon = "[~]"
        else:
            icon = "[.]"

        reqs = finding.get("pci_dss_requirements", [])
        req_ids = ", ".join(r.get("requirement_id", "?") for r in reqs)

        print(f"\n  {icon} {scan_id}: {vuln}")
        print(f"       Risk: {risk} | CWE: {finding.get('cwe', 'N/A')}")
        print(f"       PCI-DSS: {req_ids}")

        for req in reqs:
            status = req.get("compliance_status", "?")
            remed = req.get("remediation_status", "?")
            print(f"         - {req.get('requirement_id', '?')}: {status} ({remed})")

    # Summary
    print(f"\n  Executive Summary:")
    summary = assessment.get("executive_summary", "N/A")
    # Wrap at ~70 chars
    words = summary.split()
    line = "    "
    for word in words:
        if len(line) + len(word) + 1 > 70:
            print(line)
            line = "    " + word
        else:
            line += " " + word if line.strip() else "    " + word
    if line.strip():
        print(line)


def save_outputs(assessment: dict, pipeline_metadata: dict, json_path: str, md_path: str):
    """Save both JSON and Markdown compliance outputs."""
    # JSON output
    report_json = {
        "agent_name": "DevSecOps Guardian - Compliance Agent",
        "version": COMPLIANCE_VERSION,
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "repository": pipeline_metadata.get("repository", ""),
        "framework": "PCI-DSS 4.0",
        "overall_risk_rating": assessment.get("overall_risk_rating", ""),
        "compliant_count": assessment.get("compliant_count", 0),
        "non_compliant_count": assessment.get("non_compliant_count", 0),
        "executive_summary": assessment.get("executive_summary", ""),
        "findings": assessment.get("findings", []),
        "recommendations": assessment.get("recommendations", []),
    }

    os.makedirs(os.path.dirname(json_path) or ".", exist_ok=True)
    with open(json_path, "w") as f:
        json.dump(report_json, f, indent=2)
    print(f"\n  [*] JSON report saved to: {json_path}")

    # Markdown report
    md_content = generate_markdown_report(assessment, pipeline_metadata)
    os.makedirs(os.path.dirname(md_path) or ".", exist_ok=True)
    with open(md_path, "w", encoding="utf-8") as f:
        f.write(md_content)
    print(f"  [*] Markdown report saved to: {md_path}")


async def main():
    parser = argparse.ArgumentParser(description="DevSecOps Guardian - Compliance Agent")
    parser.add_argument(
        "--scanner", type=str, default=DEFAULT_SCANNER_INPUT,
        help="Path to scanner JSON output"
    )
    parser.add_argument(
        "--analyzer", type=str, default=DEFAULT_ANALYZER_INPUT,
        help="Path to analyzer JSON output"
    )
    parser.add_argument(
        "--fixer", type=str, default=DEFAULT_FIXER_INPUT,
        help="Path to fixer JSON output"
    )
    parser.add_argument(
        "--output-json", type=str, default=DEFAULT_COMPLIANCE_OUTPUT_JSON,
        help="Output JSON file path"
    )
    parser.add_argument(
        "--output-md", type=str, default=DEFAULT_COMPLIANCE_OUTPUT_MD,
        help="Output Markdown report file path"
    )

    args = parser.parse_args()

    # Header
    print(f"\n{'='*60}")
    print(f"  DevSecOps Guardian - Compliance Agent")
    print(f"  Framework: PCI-DSS 4.0")
    print(f"  Time: {datetime.now(timezone.utc).isoformat()}")
    print(f"{'='*60}\n")

    # Phase 1: Load all pipeline data
    print("[1/3] Loading pipeline data from all agents...")
    confirmed_findings, fixer_results, pipeline_metadata = load_pipeline_data(
        args.scanner, args.analyzer, args.fixer
    )
    print(f"  Confirmed findings: {len(confirmed_findings)}")
    print(f"  Fix results: {len(fixer_results)}")

    if not confirmed_findings:
        print("\n  [OK] No confirmed findings - generating clean compliance report")
        # Generate a clean assessment
        assessment = {
            "findings": [],
            "executive_summary": "No confirmed security vulnerabilities were identified. The application passed all security scans.",
            "overall_risk_rating": "LOW",
            "compliant_count": 0,
            "non_compliant_count": 0,
            "recommendations": ["Continue regular security scanning as part of SDLC."],
        }
    else:
        # Phase 2: Generate compliance assessment via LLM
        print(f"\n[2/3] Generating PCI-DSS 4.0 compliance assessment...")
        assessment = await generate_compliance_assessment(
            confirmed_findings, fixer_results, pipeline_metadata
        )

        if not assessment:
            print("  [!] Failed to generate compliance assessment - check API connection")
            sys.exit(1)

    # Phase 3: Output
    print(f"\n[3/3] Generating compliance reports...")
    print_assessment(assessment)
    save_outputs(assessment, pipeline_metadata, args.output_json, args.output_md)


if __name__ == "__main__":
    asyncio.run(main())
